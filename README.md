# ETL Performance Benchmark

A comprehensive research project comparing different ETL (Extract, Transform, Load) architectural patterns for large-scale data processing. This study evaluates sequential, bulk, multi-threaded, and edge computing approaches using real-world Stack Overflow data.

## ğŸ“Š About

This project benchmarks four distinct ETL implementation strategies to analyze their performance characteristics, resource utilization, and scalability patterns when processing millions of records. The research provides empirical evidence for choosing optimal ETL architectures based on data volume, infrastructure constraints, and performance requirements.

### Research Objectives

* Compare execution time and throughput across different ETL patterns
* Analyze memory consumption and CPU utilization for each approach
* Evaluate the benefits of edge computing in distributed data processing
* Provide actionable insights for ETL pipeline optimization

### Key Features

* **Real-world Dataset**: Uses Stack Overflow's user dataset (~650K records for testing)
* **Multiple Architectures**: Sequential, Bulk File, Multi-threaded Pipeline, and Edge Computing
* **Comprehensive Metrics**: Detailed performance logging and analysis
* **Production-Ready**: TypeScript implementation with proper error handling and logging
* **Cloud-Native**: Includes Cloudflare Workers for edge computing demonstration

## ğŸ—ï¸ Architecture Patterns

| Case   | Pattern                 | Description                                   | Use Case                        |
| ------ | ----------------------- | --------------------------------------------- | ------------------------------- |
| **1**  | Sequential              | Row-by-row processing                         | Simple, small datasets          |
| **2**  | Bulk Export/Import      | File-based batch processing                   | Large batch operations          |
| **3**  | Multi-threaded Pipeline | Concurrent processing with worker threads     | CPU-intensive transformations   |
| **4a** | Edge Computing          | Distributed processing via Cloudflare Workers | Geographically distributed data |

## ğŸ“ˆ Performance Results

With **test dataset of ~650,000 records**:

* **Sequential**: ~230s (â‰ˆ2,822 recs/sec)
* **Bulk File Import**: ~27s (â‰ˆ23,945 recs/sec)
* **Multi-threaded Pipeline**: ~134s (â‰ˆ4,861 recs/sec)
* **Edge Computing (Cloudflare Workers)**: ~30s (â‰ˆ21,895 recs/sec)

**Key Insights**: Bulk file processing offers the best throughput for large datasets, while edge computing provides excellent performance with geographical distribution benefits.

## ğŸ› ï¸ Technologies Used

* **Language**: TypeScript/Node.js
* **Database**: PostgreSQL
* **Edge Computing**: Cloudflare Workers
* **Threading**: Node.js Worker Threads
* **Package Manager**: pnpm
* **Build Tool**: tsx
* **Monitoring**: Custom performance metrics logger

## ğŸ¯ Research Applications

This benchmark is valuable for:

* Data engineers designing ETL pipelines
* Researchers studying distributed systems
* Organizations optimizing data processing workflows
* Academic courses on database systems and data engineering

## ğŸ“š Citation

If you use this research in your work, please cite:

```
@software{etl_performance_benchmark_2025,
  author = {Arnav},
  title = {ETL Performance Benchmark: A Comparative Study of Data Processing Architectures},
  year = {2025},
  url = {https://github.com/arnavgupta00/elt-khund-pipeline-benchmark}
}
```

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/arnavgupta00/elt-khund-pipeline-benchmark.git
cd elt-khund-pipeline-benchmark

# Install dependencies
pnpm install

# Set up environment variables
cp .env.template .env
# Edit .env with your database credentials

# Run specific test cases
pnpm case1    # Sequential processing
pnpm case2    # Bulk file processing
pnpm case3    # Multi-threaded pipeline
pnpm case4    # Edge computing

# Run with custom limit
pnpm start -- --case=1 --limit=10000

# Deploy edge transformer (requires Cloudflare account)
cd edge-transformer
pnpm install
pnpm deploy
```

## ğŸ“‹ Prerequisites

* Node.js (v18+)
* PostgreSQL database
* pnpm package manager
* Cloudflare account (for edge computing case)

## ğŸ“Š Sample Results

Performance comparison results are automatically saved as JSON files with detailed metrics including execution time, memory usage, and throughput statistics.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

This project is open source. Feel free to use and modify as needed.

## ğŸ”¬ Research Details

The benchmark tests were conducted using a subset of Stack Overflow's user dataset, focusing on realistic data transformation scenarios including data validation, type conversion, and aggregation operations.

---

**Keywords**: ETL, Data Pipeline, Performance Benchmark, Edge Computing, Distributed Systems, Big Data, PostgreSQL, Cloudflare Workers, TypeScript

---

## ğŸ·ï¸ **GitHub Topics to Add:**

```
etl
data-engineering
performance-testing
benchmark
postgresql
cloudflare-workers
typescript
distributed-systems
big-data
research
edge-computing
data-pipeline
multithreading
database
data-processing
```

## ğŸ“ **Repository Structure:**

```
elt-khund-pipeline-benchmark/
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package.json
â”œâ”€â”€ pnpm-lock.yaml
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts
â”‚   â”œâ”€â”€ cases/
â”‚   â”‚   â”œâ”€â”€ case1-sequential.ts
â”‚   â”‚   â”œâ”€â”€ case2-bulk.ts
â”‚   â”‚   â”œâ”€â”€ case3-pipeline.ts
â”‚   â”‚   â””â”€â”€ case4a-edge.ts
â”‚   â”œâ”€â”€ config/
â”‚   â””â”€â”€ core/
â”œâ”€â”€ edge-transformer/        # Cloudflare Workers implementation
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ wrangler.jsonc
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ research_logs/          # Performance test results (gitignored)
â””â”€â”€ temp/                   # Temporary processing files
```
